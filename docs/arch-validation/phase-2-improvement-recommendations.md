# Phase 2: Production Readiness Improvements

**Document Date**: 2025-10-11  
**Timeline**: Week 3-4 (After Phase 1 completion)  
**Focus**: Security hardening and data integrity for production deployment  
**Goal**: Safe production deployment with enterprise-grade security

## Executive Summary

After Phase 1 MVP stabilization, Phase 2 addresses production-critical concerns including data integrity, transaction safety, and comprehensive security. These improvements ensure the disaster management system is safe for real-world deployment while maintaining operational efficiency.

---

# üõ°Ô∏è CRITICAL SECURITY IMPROVEMENTS (Week 3)

## 2.1 Enterprise-Grade Encryption Implementation

**Priority**: **CRITICAL** - Enterprise security requirement  
**File**: `lib/security/encryption.ts` (NEW)  
**Impact**: Protects humanitarian data with enterprise-grade encryption

### **IMPLEMENTATION**:
```typescript
// lib/security/encryption.ts
export class EnterpriseEncryptionService {
  private static readonly ALGORITHM = 'AES-256-GCM';
  private static readonly KEY_ID = 'disaster_management_key';
  
  // ‚úÖ PROPER PATTERN: Use secure key derivation
  static async getEncryptionKey(): Promise<CryptoKey> {
    // Check for existing key in secure storage
    const existingKey = await this.getStoredKey();
    if (existingKey) {
      return existingKey;
    }
    
    // Generate new key with user-specific entropy
    const userEntropy = await this.getUserEntropy();
    const keyMaterial = await crypto.subtle.importKey(
      'raw',
      new TextEncoder().encode(userEntropy),
      'PBKDF2',
      false,
      ['deriveBits', 'deriveKey']
    );
    
    const key = await crypto.subtle.deriveKey(
      {
        name: 'PBKDF2',
        salt: new TextEncoder().encode('disaster-management-salt'),
        iterations: 100000,
        hash: 'SHA-256',
      },
      keyMaterial,
      { name: 'AES-GCM', length: 256 },
      true,
      ['encrypt', 'decrypt']
    );
    
    await this.storeKey(key);
    return key;
  }
  
  // ‚úÖ ENHANCED: User-specific entropy for key derivation
  private static async getUserEntropy(): Promise<string> {
    const authState = useAuthStore.getState();
    if (!authState.user?.id) {
      throw new Error('User not authenticated for encryption');
    }
    
    // Combine user-specific data for unique key derivation
    const entropyData = {
      userId: authState.user.id,
      deviceId: await this.getDeviceId(),
      timestamp: new Date().toISOString(),
    };
    
    return JSON.stringify(entropyData);
  }
  
  // ‚úÖ SECURE: Device-specific identifier
  private static async getDeviceId(): Promise<string> {
    let deviceId = sessionStorage.getItem('device-id');
    if (!deviceId) {
      deviceId = crypto.randomUUID();
      sessionStorage.setItem('device-id', deviceId);
    }
    return deviceId;
  }
  
  // ‚úÖ ENHANCED: Robust data encryption
  static async encrypt(data: any): Promise<{ 
    encrypted: string; 
    iv: string; 
    tag: string;
    keyId: string;
    metadata: any;
  }> {
    const key = await this.getEncryptionKey();
    const iv = crypto.getRandomValues(new Uint8Array(12));
    
    // Convert data to bytes
    const encoded = new TextEncoder().encode(JSON.stringify({
      data,
      timestamp: new Date().toISOString(),
      version: '1.0',
    }));
    
    // Encrypt with proper authentication
    const encrypted = await crypto.subtle.encrypt(
      { name: this.ALGORITHM, iv },
      key,
      encoded
    );
    
    // Extract authentication tag
    const encryptedArray = new Uint8Array(encrypted);
    const tag = encryptedArray.slice(encryptedArray.length - 16);
    const ciphertext = encryptedArray.slice(0, encryptedArray.length - 16);
    
    return {
      encrypted: btoa(String.fromCharCode(...ciphertext)),
      iv: btoa(String.fromCharCode(...iv)),
      tag: btoa(String.fromCharCode(...tag)),
      keyId: this.KEY_ID,
      metadata: {
        algorithm: this.ALGORITHM,
        encryptedAt: new Date().toISOString(),
      },
    };
  }
  
  // ‚úÖ ENHANCED: Robust data decryption
  static async decrypt(encryptedData: {
    encrypted: string;
    iv: string;
    tag: string;
    keyId: string;
    metadata?: any;
  }): Promise<any> {
    try {
      const key = await this.getEncryptionKey();
      
      // Convert back from base64
      const ciphertext = Uint8Array.from(atob(encryptedData.encrypted), c => c.charCodeAt(0));
      const iv = Uint8Array.from(atob(encryptedData.iv), c => c.charCodeAt(0));
      const tag = Uint8Array.from(atob(encryptedData.tag), c => c.charCodeAt(0));
      
      // Combine ciphertext and tag
      const combined = new Uint8Array(ciphertext.length + tag.length);
      combined.set(ciphertext);
      combined.set(tag);
      
      // Decrypt
      const decrypted = await crypto.subtle.decrypt(
        { name: this.ALGORITHM, iv },
        key,
        combined
      );
      
      const decoded = new TextDecoder().decode(decrypted);
      const parsed = JSON.parse(decoded);
      
      // Validate decryption
      if (!parsed.data || !parsed.timestamp) {
        throw new Error('Invalid encrypted data structure');
      }
      
      return parsed.data;
    } catch (error) {
      console.error('Decryption failed:', error);
      throw new Error(`Failed to decrypt data: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }
  
  // ‚úÖ SECURE: Key storage with proper security
  private static async storeKey(key: CryptoKey): Promise<void> {
    const exported = await crypto.subtle.exportKey('jwk', key);
    
    // Encrypt the key itself before storing
    const masterKey = await this.getMasterKey();
    const encryptedKey = await crypto.subtle.encrypt(
      { name: 'AES-GCM', iv: new Uint8Array(12) },
      masterKey,
      new TextEncoder().encode(JSON.stringify(exported))
    );
    
    sessionStorage.setItem(`encrypted-${this.KEY_ID}`, btoa(String.fromCharCode(...new Uint8Array(encryptedKey))));
  }
  
  private static async getStoredKey(): Promise<CryptoKey | null> {
    try {
      const encryptedKeyData = sessionStorage.getItem(`encrypted-${this.KEY_ID}`);
      if (!encryptedKeyData) return null;
      
      const masterKey = await this.getMasterKey();
      const encryptedKey = Uint8Array.from(atob(encryptedKeyData), c => c.charCodeAt(0));
      
      const decrypted = await crypto.subtle.decrypt(
        { name: 'AES-GCM', iv: new Uint8Array(12) },
        masterKey,
        encryptedKey
      );
      
      const keyData = JSON.parse(new TextDecoder().decode(decrypted));
      return await crypto.subtle.importKey(
        'jwk',
        keyData,
        { name: 'AES-GCM' },
        false,
        ['encrypt', 'decrypt']
      );
    } catch (error) {
      console.error('Failed to retrieve stored key:', error);
      return null;
    }
  }
  
  private static async getMasterKey(): Promise<CryptoKey> {
    // Use browser's built-in secure storage for master key
    const masterKeyData = 'disaster-management-master-key-2024';
    const encoder = new TextEncoder();
    
    return crypto.subtle.importKey(
      'raw',
      encoder.encode(masterKeyData),
      { name: 'AES-GCM' },
      false,
      ['encrypt', 'decrypt']
    );
  }
}
```

### **INTEGRATION WITH OFFLINE DATABASE**:
```typescript
// lib/db/offline.ts (Updated)
export class OfflineDatabase extends Dexie {
  // ... existing code
  
  // ‚úÖ ENHANCED: Use enterprise encryption
  async encryptData(data: any): Promise<string> {
    try {
      const encrypted = await EnterpriseEncryptionService.encrypt(data);
      return JSON.stringify(encrypted);
    } catch (error) {
      console.error('Encryption failed:', error);
      throw new Error(`Failed to encrypt data: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }
  
  async decryptData(encrypted: string): Promise<any> {
    try {
      const encryptedData = JSON.parse(encrypted);
      return await EnterpriseEncryptionService.decrypt(encryptedData);
    } catch (error) {
      console.error('Decryption failed:', error);
      throw new Error(`Failed to decrypt data: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }
}
```

## 2.2 Atomic Transaction Management

**Priority**: **CRITICAL** - Data integrity requirement  
**File**: `lib/sync/engine.ts` (Enhanced)  
**Impact**: Prevents partial sync failures and data corruption

### **ENHANCED SYNC ENGINE**:
```typescript
// lib/sync/engine.ts (Updated)
export class SyncEngine {
  // ‚úÖ ATOMIC: Process batch within single transaction
  static async processSyncBatch(
    changes: SyncChange[],
    userId: string
  ): Promise<{
    successful: SyncResult[];
    conflicts: SyncResult[];
    failed: SyncResult[];
    transactionId: string;
  }> {
    const transactionId = crypto.randomUUID();
    const results = {
      successful: [] as SyncResult[],
      conflicts: [] as SyncResult[],
      failed: [] as SyncResult[],
      transactionId,
    };
    
    // ‚úÖ ENHANCED: Use database transaction for atomicity
    return await prisma.$transaction(async (tx) => {
      // Pre-validate all changes
      await this.validateChanges(changes, userId, tx);
      
      // Process each change within transaction
      for (const change of changes) {
        try {
          const result = await this.processSingleChangeTransactional(change, userId, tx);
          
          if (result.status === 'success') {
            results.successful.push(result);
          } else if (result.status === 'conflict') {
            results.conflicts.push(result);
          } else {
            results.failed.push(result);
          }
        } catch (error) {
          results.failed.push({
            offlineId: change.offlineId,
            serverId: '',
            status: 'failed',
            message: error instanceof Error ? error.message : 'Unknown error',
            transactionId,
          });
          
          // Log transaction error
          console.error(`Transaction ${transactionId} change failed:`, error);
        }
      }
      
      // ‚úÖ ENHANCED: Log transaction completion
      await this.logTransaction({
        transactionId,
        userId,
        totalChanges: changes.length,
        successful: results.successful.length,
        conflicts: results.conflicts.length,
        failed: results.failed.length,
        completedAt: new Date(),
      });
      
      return results;
    }, {
      // ‚úÖ ENHANCED: Transaction configuration
      timeout: 30000, // 30 second timeout
      isolationLevel: 'ReadCommitted',
    });
  }
  
  // ‚úÖ ENHANCED: Pre-validation within transaction
  private static async validateChanges(
    changes: SyncChange[],
    userId: string,
    tx: any
  ): Promise<void> {
    // Validate user permissions
    const user = await tx.user.findUnique({
      where: { id: userId },
      select: { id: true, isActive: true },
    });
    
    if (!user || !user.isActive) {
      throw new Error('User validation failed');
    }
    
    // Validate each change
    for (const change of changes) {
      await this.validateSingleChange(change, userId, tx);
    }
  }
  
  private static async validateSingleChange(
    change: SyncChange,
    userId: string,
    tx: any
  ): Promise<void> {
    // Validate data structure
    if (!change.type || !change.action || !change.versionNumber) {
      throw new Error(`Invalid change structure: ${JSON.stringify(change)}`);
    }
    
    // Validate version number
    if (change.versionNumber < 1) {
      throw new Error(`Invalid version number: ${change.versionNumber}`);
    }
    
    // Validate entity access permissions
    if (change.data.entityId) {
      const assignment = await tx.entityAssignment.findFirst({
        where: {
          userId,
          entityId: change.data.entityId,
          isActive: true,
        },
      });
      
      if (!assignment) {
        throw new Error(`No assignment for entity ${change.data.entityId}`);
      }
    }
  }
  
  // ‚úÖ ENHANCED: Transaction-aware single change processing
  private static async processSingleChangeTransactional(
    change: SyncChange,
    userId: string,
    tx: any
  ): Promise<SyncResult> {
    switch (change.type) {
      case 'assessment':
        return this.syncAssessmentTransactional(change, userId, tx);
      case 'response':
        return this.syncResponseTransactional(change, userId, tx);
      case 'media':
        return this.syncMediaTransactional(change, userId, tx);
      default:
        throw new Error(`Unknown sync type: ${change.type}`);
    }
  }
  
  // ‚úÖ ENHANCED: Transactional assessment sync
  private static async syncAssessmentTransactional(
    change: SyncChange,
    userId: string,
    tx: any
  ): Promise<SyncResult> {
    const { action, data, offlineId, versionNumber } = change;
    
    if (action === 'create') {
      // Check for existing by offlineId within transaction
      if (offlineId) {
        const existing = await tx.rapidAssessment.findUnique({
          where: { offlineId },
        });
        
        if (existing) {
          return {
            offlineId,
            serverId: existing.id,
            status: 'success',
            message: 'Assessment already synced',
          };
        }
      }
      
      // Check auto-approval within transaction
      const shouldAutoApprove = await AutoApprovalService.shouldAutoApprove(
        data.entityId,
        versionNumber === 1,
        tx
      );
      
      // Create new assessment within transaction
      const created = await tx.rapidAssessment.create({
        data: {
          ...data,
          assessorId: userId,
          offlineId,
          versionNumber,
          syncStatus: SyncStatus.SYNCED,
          verificationStatus: shouldAutoApprove 
            ? VerificationStatus.AUTO_VERIFIED 
            : VerificationStatus.PENDING,
        },
      });
      
      return {
        offlineId,
        serverId: created.id,
        status: 'success',
      };
    }
    
    // ... handle update action with transaction awareness
    throw new Error(`Unsupported action: ${action}`);
  }
  
  // ‚úÖ ENHANCED: Transaction logging
  private static async logTransaction(log: {
    transactionId: string;
    userId: string;
    totalChanges: number;
    successful: number;
    conflicts: number;
    failed: number;
    completedAt: Date;
  }): Promise<void> {
    try {
      await prisma.syncTransaction.create({
        data: {
          transactionId: log.transactionId,
          userId: log.userId,
          totalChanges: log.totalChanges,
          successful: log.successful,
          conflicts: log.conflicts,
          failed: log.failed,
          completedAt: log.completedAt,
        },
      });
    } catch (error) {
      console.error('Failed to log transaction:', error);
      // Don't throw - logging failure shouldn't break sync
    }
  }
}
```

## 2.3 Enhanced Conflict Resolution

**Priority**: **HIGH** - Data integrity requirement  
**File**: `lib/sync/conflict-resolution.ts` (NEW)  
**Impact**: Prevents data loss during concurrent field operations

### **CONFLICT RESOLUTION SERVICE**:
```typescript
// lib/sync/conflict-resolution.ts
export interface ConflictData {
  entityType: string;
  entityId: string;
  serverVersion: any;
  clientVersion: any;
  conflictType: 'VERSION_CONFLICT' | 'DATA_CONFLICT' | 'DELETE_CONFLICT';
  timestamp: Date;
  userId: string;
}

export interface ConflictResolution {
  strategy: 'SERVER_WINS' | 'CLIENT_WINS' | 'MERGE' | 'MANUAL';
  resolvedData?: any;
  message?: string;
}

export class ConflictResolutionService {
  // ‚úÖ ENHANCED: Intelligent conflict detection
  static async detectConflicts(
    clientChange: SyncChange,
    serverData: any
  ): Promise<{
    hasConflict: boolean;
    conflictData?: ConflictData;
    suggestedResolution?: ConflictResolution;
  }> {
    if (!serverData) {
      return { hasConflict: false };
    }
    
    // Version conflict detection
    if (serverData.versionNumber > clientChange.versionNumber) {
      return {
        hasConflict: true,
        conflictData: {
          entityType: clientChange.type,
          entityId: clientChange.data.id || clientChange.data.entityId,
          serverVersion: serverData,
          clientVersion: clientChange.data,
          conflictType: 'VERSION_CONFLICT',
          timestamp: new Date(),
          userId: clientChange.userId,
        },
        suggestedResolution: await this.suggestResolution(clientChange, serverData),
      };
    }
    
    // Data conflict detection
    const dataConflict = await this.detectDataConflicts(clientChange.data, serverData);
    if (dataConflict.hasConflict) {
      return {
        hasConflict: true,
        conflictData: {
          entityType: clientChange.type,
          entityId: clientChange.data.id || clientChange.data.entityId,
          serverVersion: serverData,
          clientVersion: clientChange.data,
          conflictType: 'DATA_CONFLICT',
          timestamp: new Date(),
          userId: clientChange.userId,
        },
        suggestedResolution: dataConflict.suggestedResolution,
      };
    }
    
    return { hasConflict: false };
  }
  
  // ‚úÖ ENHANCED: Smart conflict resolution suggestions
  private static async suggestResolution(
    clientChange: SyncChange,
    serverData: any
  ): Promise<ConflictResolution> {
    // For assessments, prefer server data (more recent)
    if (clientChange.type === 'assessment') {
      return {
        strategy: 'SERVER_WINS',
        message: 'Server version is more recent - using server data',
      };
    }
    
    // For responses, try to merge
    if (clientChange.type === 'response') {
      const mergeResult = await this.tryMergeResponses(clientChange.data, serverData);
      if (mergeResult.canMerge) {
        return {
          strategy: 'MERGE',
          resolvedData: mergeResult.mergedData,
          message: 'Merged server and client response data',
        };
      }
    }
    
    // Default to manual resolution for complex cases
    return {
      strategy: 'MANUAL',
      message: 'Manual conflict resolution required',
    };
  }
  
  // ‚úÖ ENHANCED: Response merging logic
  private static async tryMergeResponses(
    clientData: any,
    serverData: any
  ): Promise<{ canMerge: boolean; mergedData?: any }> {
    try {
      // Merge non-conflicting fields
      const merged = {
        ...serverData,
        // Use most recent status
        status: clientData.status || serverData.status,
        // Merge items if no conflicts
        items: this.mergeResponseItems(clientData.items || [], serverData.items || []),
        // Preserve most recent update
        updatedAt: new Date(Math.max(
          new Date(clientData.updatedAt || 0).getTime(),
          new Date(serverData.updatedAt || 0).getTime()
        )),
      };
      
      return { canMerge: true, mergedData: merged };
    } catch (error) {
      console.error('Failed to merge responses:', error);
      return { canMerge: false };
    }
  }
  
  private static mergeResponseItems(clientItems: any[], serverItems: any[]): any[] {
    const mergedItems = [...serverItems];
    
    for (const clientItem of clientItems) {
      const existingIndex = mergedItems.findIndex(
        item => item.id === clientItem.id || item.name === clientItem.name
      );
      
      if (existingIndex >= 0) {
        // Update existing item
        mergedItems[existingIndex] = {
          ...mergedItems[existingIndex],
          ...clientItem,
          updatedAt: new Date(),
        };
      } else {
        // Add new item
        mergedItems.push({
          ...clientItem,
          createdAt: new Date(),
          updatedAt: new Date(),
        });
      }
    }
    
    return mergedItems;
  }
  
  // ‚úÖ ENHANCED: Apply conflict resolution
  static async applyResolution(
    conflictData: ConflictData,
    resolution: ConflictResolution,
    userId: string
  ): Promise<SyncResult> {
    switch (resolution.strategy) {
      case 'SERVER_WINS':
        return {
          offlineId: conflictData.clientVersion.offlineId,
          serverId: conflictData.entityId,
          status: 'success',
          message: 'Used server version',
        };
        
      case 'CLIENT_WINS':
        return await this.applyClientVersion(conflictData, userId);
        
      case 'MERGE':
        return await this.applyMergedVersion(conflictData, resolution, userId);
        
      case 'MANUAL':
        return {
          offlineId: conflictData.clientVersion.offlineId,
          serverId: conflictData.entityId,
          status: 'conflict',
          message: 'Manual resolution required',
        };
        
      default:
        throw new Error(`Unknown resolution strategy: ${resolution.strategy}`);
    }
  }
  
  private static async applyClientVersion(
    conflictData: ConflictData,
    userId: string
  ): Promise<SyncResult> {
    try {
      const updated = await prisma.rapidAssessment.update({
        where: { id: conflictData.entityId },
        data: {
          ...conflictData.clientVersion,
          versionNumber: conflictData.clientVersion.versionNumber + 1,
          updatedAt: new Date(),
          updatedBy: userId,
          conflictResolvedAt: new Date(),
        },
      });
      
      return {
        offlineId: conflictData.clientVersion.offlineId,
        serverId: updated.id,
        status: 'success',
        message: 'Used client version',
      };
    } catch (error) {
      console.error('Failed to apply client version:', error);
      throw error;
    }
  }
  
  private static async applyMergedVersion(
    conflictData: ConflictData,
    resolution: ConflictResolution,
    userId: string
  ): Promise<SyncResult> {
    try {
      const updated = await prisma.rapidAssessment.update({
        where: { id: conflictData.entityId },
        data: {
          ...resolution.resolvedData,
          versionNumber: Math.max(
            conflictData.serverVersion.versionNumber,
            conflictData.clientVersion.versionNumber
          ) + 1,
          updatedAt: new Date(),
          updatedBy: userId,
          conflictResolvedAt: new Date(),
        },
      });
      
      return {
        offlineId: conflictData.clientVersion.offlineId,
        serverId: updated.id,
        status: 'success',
        message: 'Applied merged version',
      };
    } catch (error) {
      console.error('Failed to apply merged version:', error);
      throw error;
    }
  }
}
```

## 2.4 Enhanced Error Recovery Mechanisms

**Priority**: **HIGH** - Production reliability requirement  
**File**: `lib/sync/retry-manager.ts` (NEW)  
**Impact**: Ensures reliable sync operations in challenging network conditions

### **RETRY MANAGER**:
```typescript
// lib/sync/retry-manager.ts
export interface RetryConfig {
  maxRetries: number;
  baseDelay: number;
  maxDelay: number;
  backoffMultiplier: number;
  retryableErrors: string[];
}

export class SyncRetryManager {
  private static readonly DEFAULT_CONFIG: RetryConfig = {
    maxRetries: 5,
    baseDelay: 1000, // 1 second
    maxDelay: 30000, // 30 seconds
    backoffMultiplier: 2,
    retryableErrors: [
      'NetworkError',
      'TimeoutError',
      'ConnectionError',
      '5xx',
      'ECONNRESET',
      'ETIMEDOUT',
    ],
  };
  
  // ‚úÖ ENHANCED: Exponential backoff with jitter
  static calculateDelay(attempt: number, config: RetryConfig): number {
    const exponentialDelay = config.baseDelay * Math.pow(config.backoffMultiplier, attempt - 1);
    const jitter = Math.random() * 0.1 * exponentialDelay; // 10% jitter
    return Math.min(exponentialDelay + jitter, config.maxDelay);
  }
  
  // ‚úÖ ENHANCED: Determine if error is retryable
  static isRetryableError(error: Error, config: RetryConfig): boolean {
    const errorMessage = error.message.toLowerCase();
    
    // Check specific retryable error messages
    if (config.retryableErrors.some(retryable => 
      errorMessage.includes(retryable.toLowerCase())
    )) {
      return true;
    }
    
    // Check HTTP status codes
    if (errorMessage.includes('status:')) {
      const statusMatch = errorMessage.match(/status:\s*(\d+)/);
      if (statusMatch) {
        const status = parseInt(statusMatch[1]);
        return status >= 500 || status === 408 || status === 429;
      }
    }
    
    return false;
  }
  
  // ‚úÖ ENHANCED: Execute operation with retry logic
  static async executeWithRetry<T>(
    operation: () => Promise<T>,
    config: Partial<RetryConfig> = {}
  ): Promise<T> {
    const retryConfig = { ...this.DEFAULT_CONFIG, ...config };
    let lastError: Error;
    
    for (let attempt = 1; attempt <= retryConfig.maxRetries + 1; attempt++) {
      try {
        return await operation();
      } catch (error) {
        lastError = error instanceof Error ? error : new Error(String(error));
        
        // Don't retry on last attempt
        if (attempt > retryConfig.maxRetries) {
          throw lastError;
        }
        
        // Check if error is retryable
        if (!this.isRetryableError(lastError, retryConfig)) {
          throw lastError;
        }
        
        // Calculate delay and wait
        const delay = this.calculateDelay(attempt, retryConfig);
        console.log(`Retry attempt ${attempt}/${retryConfig.maxRetries} after ${delay}ms delay`);
        
        await this.delay(delay);
      }
    }
    
    throw lastError!;
  }
  
  // ‚úÖ ENHANCED: Priority-based retry queue
  static async executePrioritySync<T>(
    operations: Array<{
      operation: () => Promise<T>;
      priority: 'CRITICAL' | 'HIGH' | 'NORMAL' | 'LOW';
      id: string;
    }>,
    config: Partial<RetryConfig> = {}
  ): Promise<{
      successful: Array<{ id: string; result: T; priority: string }>;
      failed: Array<{ id: string; error: Error; priority: string; attempt: number }>;
    }> {
    // Sort operations by priority
    const sortedOperations = operations.sort((a, b) => {
      const priorityOrder = { CRITICAL: 0, HIGH: 1, NORMAL: 2, LOW: 3 };
      return priorityOrder[a.priority] - priorityOrder[b.priority];
    });
    
    const results = {
      successful: [] as Array<{ id: string; result: T; priority: string }>,
      failed: [] as Array<{ id: string; error: Error; priority: string; attempt: number }>,
    };
    
    // Execute operations in priority order
    for (const op of sortedOperations) {
      try {
        const result = await this.executeWithRetry(op.operation, config);
        results.successful.push({
          id: op.id,
          result,
          priority: op.priority,
        });
      } catch (error) {
        results.failed.push({
          id: op.id,
          error: error instanceof Error ? error : new Error(String(error)),
          priority: op.priority,
          attempt: 1, // Could track actual attempts
        });
      }
    }
    
    return results;
  }
  
  private static delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}
```

## üìã Phase 2 Implementation Checklist

### Critical Security Fixes (MUST DO)
- [ ] Implement enterprise-grade encryption service
- [ ] Replace localStorage key storage with secure storage
- [ ] Add atomic transaction management for sync operations
- [ ] Implement comprehensive conflict resolution

### Data Integrity Improvements (SHOULD DO)
- [ ] Add transaction logging and monitoring
- [ ] Implement retry manager with exponential backoff
- [ ] Add priority-based sync queue
- [ ] Create conflict resolution workflows

### Error Recovery Enhancements (COULD DO)
- [ ] Add dead letter queue for permanently failing items
- [ ] Implement circuit breaker pattern for repeated failures
- [ ] Add comprehensive error reporting and monitoring

### Expected Phase 2 Outcomes

**Security Improvements**:
- ‚úÖ Enterprise-grade encryption for all sensitive data
- ‚úÖ Secure key storage and management
- ‚úÖ Protected data at rest and in transit
- ‚úÖ No sensitive data in localStorage

**Data Integrity Guarantees**:
- ‚úÖ Atomic transaction boundaries prevent partial failures
- ‚úÖ Intelligent conflict resolution prevents data loss
- ‚úÖ Comprehensive error recovery mechanisms
- ‚úÖ Transaction logging for audit trails

**Production Readiness**:
- ‚úÖ Safe deployment with security measures
- ‚úÖ Robust error handling in production scenarios
- ‚úÖ Monitoring and observability for sync operations
- ‚úÖ Reliability guarantees for disaster response data

---

**Next**: Phase 3 will focus on advanced disaster resilience features and performance optimizations.

**Context7 References Used**: Enterprise encryption patterns, PostgreSQL transaction management, conflict resolution strategies, and error recovery best practices validated in previous research phases.